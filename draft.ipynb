{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from data_utils import load_CIFAR_data, generate_partial_data, generate_bal_private_data\n",
    "from FedMD import FedMD\n",
    "from Neural_Networks import train_models, cnn_2layer_fc_model, cnn_3layer_fc_model\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import clone_model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "from data_utils import generate_alignment_data\n",
    "from Neural_Networks import remove_last_layer\n",
    "from utility import * "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "CANDIDATE_MODELS = {\"2_layer_CNN\": cnn_2layer_fc_model, \n",
    "                    \"3_layer_CNN\": cnn_3layer_fc_model} \n",
    "\n",
    "conf_file = os.path.abspath(\"conf/CIFAR_balance_conf.json\")\n",
    "\n",
    "with open(conf_file, \"r\") as f:\n",
    "    conf_dict = eval(f.read())\n",
    "    \n",
    "    #n_classes = conf_dict[\"n_classes\"]\n",
    "    model_config = conf_dict[\"models\"]\n",
    "    pre_train_params = conf_dict[\"pre_train_params\"]\n",
    "    model_saved_dir = conf_dict[\"model_saved_dir\"]\n",
    "    model_saved_names = conf_dict[\"model_saved_names\"]\n",
    "    is_early_stopping = conf_dict[\"early_stopping\"]\n",
    "    public_classes = conf_dict[\"public_classes\"]\n",
    "    private_classes = conf_dict[\"private_classes\"]\n",
    "    n_classes = len(public_classes) + len(private_classes)\n",
    "    \n",
    "    emnist_data_dir = conf_dict[\"EMNIST_dir\"]    \n",
    "    N_parties = conf_dict[\"N_parties\"]\n",
    "    N_samples_per_class = conf_dict[\"N_samples_per_class\"]\n",
    "    \n",
    "    N_rounds = conf_dict[\"N_rounds\"]\n",
    "    N_alignment = conf_dict[\"N_alignment\"]\n",
    "    N_private_training_round = conf_dict[\"N_private_training_round\"]\n",
    "    private_training_batchsize = conf_dict[\"private_training_batchsize\"]\n",
    "    N_logits_matching_round = conf_dict[\"N_logits_matching_round\"]\n",
    "    logits_matching_batchsize = conf_dict[\"logits_matching_batchsize\"]\n",
    "    aug = conf_dict[\"aug\"]\n",
    "    compress = conf_dict[\"compress\"]\n",
    "    \n",
    "    \n",
    "    result_save_dir = conf_dict[\"result_save_dir\"]\n",
    "\n",
    "del conf_dict, conf_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (50000, 32, 32, 3)\n",
      "X_test shape : (10000, 32, 32, 3)\n",
      "y_train shape : (50000,)\n",
      "y_test shape : (10000,)\n",
      "X_train shape : (50000, 32, 32, 3)\n",
      "X_test shape : (10000, 32, 32, 3)\n",
      "y_train shape : (50000,)\n",
      "y_test shape : (10000,)\n",
      "X shape : (3000, 32, 32, 3)\n",
      "y shape : (3000,)\n",
      "X shape : (600, 32, 32, 3)\n",
      "y shape : (600,)\n",
      "10    500\n",
      "15    500\n",
      "14    500\n",
      "12    500\n",
      "13    500\n",
      "11    500\n",
      "dtype: int64\n",
      "============================================================\n",
      "============================================================\n",
      "X shape : (600, 32, 32, 3)\n",
      "y shape : (600,)\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 18:09:31.804952: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-15 18:09:31.806026: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/gadmohamed/miniforge3/envs/env_tf/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of model_0: 1000.704\n",
      "size of model_1: 2148.864\n",
      "size of model_2: 2148.864\n",
      "size of model_3: 1000.704\n",
      "size of model_4: 1000.704\n",
      "size of model_5: 1474.048\n",
      "size of model_6: 1140.992\n",
      "size of model_7: 400.644\n",
      "size of model_8: 446.208\n",
      "size of model_9: 409.344\n",
      "size of model_10: 4887.552\n",
      "size of model_11: 2148.864\n",
      "size of model_12: 2148.864\n",
      "size of model_13: 1000.704\n",
      "size of model_14: 1000.704\n",
      "size of model_15: 1474.048\n",
      "size of model_16: 1140.992\n",
      "size of model_17: 400.644\n",
      "size of model_18: 446.208\n",
      "size of model_19: 409.344\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train_CIFAR10, y_train_CIFAR10, X_test_CIFAR10, y_test_CIFAR10 \\\n",
    "= load_CIFAR_data(data_type=\"CIFAR10\", \n",
    "                    standarized = True, verbose = True)\n",
    "\n",
    "public_dataset = {\"X\": X_train_CIFAR10, \"y\": y_train_CIFAR10}\n",
    "\n",
    "\n",
    "X_train_CIFAR100, y_train_CIFAR100, X_test_CIFAR100, y_test_CIFAR100 \\\n",
    "= load_CIFAR_data(data_type=\"CIFAR100\",\n",
    "                    standarized = True, verbose = True)\n",
    "\n",
    "# only use those CIFAR100 data whose y_labels belong to private_classes\n",
    "X_train_CIFAR100, y_train_CIFAR100 \\\n",
    "= generate_partial_data(X = X_train_CIFAR100, y= y_train_CIFAR100,\n",
    "                        class_in_use = private_classes, \n",
    "                        verbose = True)\n",
    "\n",
    "\n",
    "X_test_CIFAR100, y_test_CIFAR100 \\\n",
    "= generate_partial_data(X = X_test_CIFAR100, y= y_test_CIFAR100,\n",
    "                        class_in_use = private_classes, \n",
    "                        verbose = True)\n",
    "\n",
    "# relabel the selected CIFAR100 data for future convenience\n",
    "for index, cls_ in enumerate(private_classes):        \n",
    "    y_train_CIFAR100[y_train_CIFAR100 == cls_] = index + len(public_classes)\n",
    "    y_test_CIFAR100[y_test_CIFAR100 == cls_] = index + len(public_classes)\n",
    "del index, cls_\n",
    "\n",
    "print(pd.Series(y_train_CIFAR100).value_counts())\n",
    "mod_private_classes = np.arange(len(private_classes)) + len(public_classes)\n",
    "\n",
    "print(\"=\"*60)\n",
    "#generate private data\n",
    "private_data, total_private_data\\\n",
    "=generate_bal_private_data(X_train_CIFAR100, y_train_CIFAR100,      \n",
    "                            N_parties = N_parties,           \n",
    "                            classes_in_use = mod_private_classes, \n",
    "                            N_samples_per_class = N_samples_per_class, \n",
    "                            data_overlap = False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "X_tmp, y_tmp = generate_partial_data(X = X_test_CIFAR100, y= y_test_CIFAR100,\n",
    "                                        class_in_use = mod_private_classes, \n",
    "                                        verbose = True)\n",
    "private_test_data = {\"X\": X_tmp, \"y\": y_tmp}\n",
    "del X_tmp, y_tmp\n",
    "\n",
    "parties = []\n",
    "if model_saved_dir is None:\n",
    "    for i, item in enumerate(model_config):\n",
    "        model_name = item[\"model_type\"]\n",
    "        model_params = item[\"params\"]\n",
    "        tmp = CANDIDATE_MODELS[model_name](n_classes=n_classes, \n",
    "                                            input_shape=(32,32,3),\n",
    "                                            **model_params)\n",
    "        print(\"size of model_{}: {}\".format(i, size_of(tmp)))\n",
    "        parties.append(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50.0, 50000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_of(public_dataset['y']), len(public_dataset['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  0\n",
      "model  1\n",
      "model  2\n",
      "model  3\n",
      "model  4\n",
      "model  5\n",
      "model  6\n",
      "model  7\n",
      "model  8\n",
      "model  9\n",
      "model  10\n",
      "model  11\n",
      "model  12\n",
      "model  13\n",
      "model  14\n",
      "model  15\n",
      "model  16\n",
      "model  17\n",
      "model  18\n",
      "model  19\n",
      "augmenting public dataset ... \n",
      "round  0\n",
      "update logits ... \n",
      "aug:True, compress:False, N_alignment:1000\n",
      "collaborative parties 20\n",
      "size of alignment data 8.0, length: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 18:09:42.980971: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-05-15 18:09:43.141330: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-15 18:09:43.537894: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-15 18:09:43.965784: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-15 18:09:44.338528: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-15 18:09:44.649701: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-15 18:09:44.962498: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-15 18:09:45.383543: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-15 18:09:45.786222: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-15 18:09:46.113552: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-15 18:09:46.478103: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-15 18:09:46.769391: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-15 18:09:47.586150: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-15 18:09:48.003447: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-15 18:09:48.377000: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-15 18:09:48.692180: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-15 18:09:49.005804: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-15 18:09:49.443325: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-15 18:09:49.898787: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-15 18:09:50.243719: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-15 18:09:50.619710: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of local soft labels:64.0, size of global soft labels:64.0\n",
      "length of local soft labels:1000, length of global soft labels:1000\n",
      "type of local soft labels:float32, type of global soft labels:float32\n"
     ]
    }
   ],
   "source": [
    "fedmd = FedMD(parties, \n",
    "                public_dataset = public_dataset,\n",
    "                private_data = private_data, \n",
    "                total_private_data = total_private_data,\n",
    "                private_test_data = private_test_data,\n",
    "                N_rounds = N_rounds,\n",
    "                N_alignment = N_alignment, \n",
    "                N_logits_matching_round = N_logits_matching_round,\n",
    "                logits_matching_batchsize = logits_matching_batchsize, \n",
    "                N_private_training_round = N_private_training_round, \n",
    "                private_training_batchsize = private_training_batchsize, aug = aug, compress = compress) \n",
    "\n",
    "# initialization_result = fedmd.init_result\n",
    "# pooled_train_result = fedmd.pooled_train_result\n",
    "\n",
    "collaboration_performance = fedmd.collaborative_training()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "local_trials = []\n",
    "for i, item in enumerate(model_config):\n",
    "    model_name = item[\"model_type\"]\n",
    "    model_params = item[\"params\"]\n",
    "    trials = [] \n",
    "    for trail in range(3) : \n",
    "        tf.keras.backend.clear_session()\n",
    "        model_l = CANDIDATE_MODELS[model_name](n_classes=n_classes, \n",
    "                                            input_shape=(32,32,3),\n",
    "                                            **model_params)\n",
    "        model_l.compile(optimizer=tf.keras.optimizers.Adam(lr = 1e-5),\n",
    "                            loss = \"sparse_categorical_crossentropy\", \n",
    "                            metrics = [\"accuracy\"])\n",
    "\n",
    "        ub_history = model_l.fit(private_data[i][\"X\"], private_data[i][\"y\"],\n",
    "                        batch_size = 32, epochs = 50, shuffle=True, verbose = False, \n",
    "                        validation_data = [private_test_data[\"X\"], private_test_data[\"y\"]],\n",
    "                        callbacks=[EarlyStopping(monitor=\"val_accuracy\", min_delta=0.0001, patience=10, restore_best_weights=True)])\n",
    "        trials.append(ub_history.history[\"val_accuracy\"][-1])\n",
    "        print(\"trail {0} : {1}\".format(trail, trials[-1]))\n",
    "    avg_trial = np.mean(trials)\n",
    "    local_trials.append(avg_trial)\n",
    "    print(\"trials for model {0}: {1}\".format(i, trials))\n",
    "    print(\"Average of model {0} trials: {1}\".format(i, avg_trial))\n",
    "    print() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(local_trials)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
